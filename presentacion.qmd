---
title: "Entrega Final - Series Cronológicas"
subtitle: "Facultad de Ciencias Económicas y Administración - 2025 - UDeLaR"
author: "Leandro Berrueta, Lucca Frachelle, Cecilia Waksman"
# date: today
fig-align: center
warning: false
message: false
echo: false
eval: true
embed-resources: true
mainfont: Arial
sansfont: Arial
format:
  revealjs: 
    theme: white
    slide-number: c
    slide-level: 3
    show-slide-number: all
    hash: true
fontsize: 18pt
---

```{r}
# Paquetes:
library(forecast)
library(tidyverse)
library(tseries)
library(forecast)
library(urca)
library(lmtest)
library(gridExtra)
library(seasonal)
library(readxl)
library(knitr)
library(kableExtra)
library(broom)
library(tseries)
library(gtsummary)
library(latex2exp) # Permite usar TeX() para incluir elementos LaTeX en ggplots.
library(tsoutliers) # Permite chequear outliers mediante funciones.
#library(RJDemetra)

# Función para agregar p-valores a modelos Arima para gtsummary
tidy_arima <- function(x, ...) {
  # tidy the model
  ret <- broom::tidy(x, ...)
  
  # calculate p-values
  ret$p.value <- 2 * pnorm(abs(ret$estimate / ret$std.error), lower.tail = FALSE)
  
  # return tidied tibble
  ret
}
```

```{r}
df <- read_excel("data/series_bcu.xlsx" , sheet = "cantidad_personas_deuda_vigente") %>%
  select(fecha, cantidad_clientes, tipoinstitucion) %>%
  filter(tipoinstitucion == "Santander")
cantidad_clientes_ts <- ts(df$cantidad_clientes, start = c(2018, 12), end = c(2024, 12), frequency = 12)
cantidad_clientes_ts_completa <- ts(df$cantidad_clientes, start = c(2018, 12), frequency = 12) 
# Se deja 3 observaciones para predicción
```

# Introducción

El presente trabajo se desarrollará en base a la serie mensual de la cantidad de clientes con deuda vigente en el Banco Santander durante el período de Diciembre 2018 a Marzo 2025, proveniente de la central de riesgos que se informa al Banco Central del Uruguay (BCU). 

La serie se encuentra constituida por 76 observaciones. 

Dada la baja cantidad de observaciones disponibles se utilizará, a los efectos de identificar el modelo que logre representar el comportamiento de la serie, los datos de hasta Diciembre del 2024 inclusive (73 observaciones en total). 

Las tres observaciones restantes, referidas al año 2025, serán utilizadas con el fin de contrastar el desempeño de la predicción.

## Gráfico de la Serie Temporal

```{r}
#| fig-align: center
cantidad_clientes_ts %>%
  autoplot() +
  ggtitle("Serie de Clientes con Deuda") +
  xlab("Fecha") +
  ylab("Cantidad de Clientes") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

# Identificación del Modelo

### Análisis en el Dominio del Tiempo: Función de Autocorrelación (FAC)

```{r}
#| fig-align: center
clientes_acf <- ggAcf(cantidad_clientes_ts, lag.max = 24, type = "correlation") + 
  labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "Función de Autocorrelación (FAC)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

clientes_acf
```

La FAC decrece lentamente y de forma persistente, con coeficientes de autocorrelación significativos que se mantienen altos incluso en los mayores rezagos y que, por ende, no se comportan de acuerdo al decaimiento exponencial que caracteriza a las series débilmente estacionarias.

Además, las autocorrelaciones significativas en rezagos altos sugieren la presencia de una tendencia.

### Análisis en el Dominio del Tiempo: Función de Autocorrelación Parcial (FACP)

```{r}
#| fig-align: center
clientes_pacf <- ggAcf(cantidad_clientes_ts, lag.max = 24, type = "partial") + 
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "Función de Autocorrelación Parcial (FACP)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

clientes_pacf
```

La FACP muestra un coeficiente significativo en el primer rezago y luego decae rápidamente, no habiendo otro rezago que resulte significativo al nivel de significación usual del 5%. 

Se concluye de este primer análisis del Dominio del Tiempo en la posibilidad de aplicar, al menos, una Primera Diferencia Regular a la misma.


### Análisis en el Dominio de Frecuencias de la Serie Original

```{r}
#| fig-align: center
# Periodograma de la Serie:
Espectro_Serie <- spectrum(cantidad_clientes_ts, method = c("pgram"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = FALSE) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Tibble <- tibble(Frecuencias = Espectro_Serie$freq*pi/max(Espectro_Serie$freq),
                                Espectro = Espectro_Serie$spec)
# Plot:
Plot_Espectro <- ggplot(Espectro_Serie_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma de la Serie)"),
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))

# Espectro de la Serie:
Espectro_Serie <- spectrum(cantidad_clientes_ts, method = c("ar"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = FALSE) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Tibble <- tibble(Frecuencias = Espectro_Serie$freq*pi/max(Espectro_Serie$freq),
                                Espectro = Espectro_Serie$spec)
# Plot:
Plot_Espectro_Suavizado <- ggplot(Espectro_Serie_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma Suavizado de la Serie)"),
       subtitle = "Método: AR(1)",
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))
Plot_Espectro_Suavizado
```

Mediante el Periodograma Suavizado de la serie es posible respaldar la idea de que la misma presenta una tendencia que debería ser modelada. 

En particular, las frecuencias más próximas a $0$, y por ende las asociadas a ciclos de período próximo a infinito (el componente tendencial) explican la mayor parte de la variabilidad de la serie.

# Contrastes de Raíces Unitarias

- Contraste de Dickey-Fuller Aumentado (DF o DFA)

- Kwiatkowski-Phillips-Schmidt-Shin (KPSS).

## Dickey-Fuller Aumentado

```{r}
DF_Serie_Original <- ur.df(y = cantidad_clientes_ts, type = "trend", lags = 2)

# Tabla de estadísticos y valores críticos
df_results <- data.frame(
  "Estadístico" = DF_Serie_Original@teststat[1,],
  "VC 1%" = DF_Serie_Original@cval[,1],
  "VC 5%" = DF_Serie_Original@cval[,2],
  "VC 10%" = DF_Serie_Original@cval[,3]
)
rownames(df_results) <- c("tau3 (con tendencia)", "phi2", "phi3")

kable(df_results, caption = "Resultados del Test de Dickey-Fuller Aumentado")
```

\

No se rechaza la Hipótesis Nula de que la serie presente una raíz unitaria a ninguno de los niveles de significación planteados. De esta manera se tiene un respaldo estadístico para aplicar la Primera Diferencia Regular.

## KPSS

```{r}
KPSS_Serie_Original <- ur.kpss(y = cantidad_clientes_ts, type = "tau")

kpss_results_df <- data.frame(
  Item = c("Estadístico de Test", "Valor Crítico 10%", "Valor Crítico 5%", "Valor Crítico 2.5%", "Valor Crítico 1%"),
  Valor = c(KPSS_Serie_Original@teststat, KPSS_Serie_Original@cval[1], KPSS_Serie_Original@cval[2], KPSS_Serie_Original@cval[3], KPSS_Serie_Original@cval[4])
)
kable(kpss_results_df, caption = "Resultados del Test KPSS (con tendencia)")
```

\

Como resultado se rechaza la Hipótesis Nula de que la serie sea Integrada de Orden $0$, lo que nuevamente da un respaldo estadístico para la aplicación de la Primera Diferencia Regular en los datos.


### Serie Diferenciada de acuerdo a la Primera Diferencia Regular

```{r}
#| fig-align: center
diff_cantidad_clientes_ts <- diff(cantidad_clientes_ts, differences = 1)
autoplot(diff_cantidad_clientes_ts) + 
  labs(x = "Fecha", y = "Cantidad de \n       Personas", 
       title = "Serie de Cantidad de Personas con\n       Deuda en Santander",
       subtitle = "Primera Diferencia Regular") +
  geom_hline(aes(yintercept = mean(diff_cantidad_clientes_ts)), colour = "red") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

## Serie Diferenciada de acuerdo a la Primera Diferencia Regular

La Primera Diferencia Regular adquiere un comportamiento más próximo al estacionario que la serie original. 

- La tendencia ha sido eliminada.

- La Media parece ser constante.

- La Varianza no se comporta de forma constante, lo que sugiere la posible presencia de datos atípicos, particularmente a fines de los años 2019, 2021 y 2023.

Considerando los años por separado, la serie diferenciada se comporta de forma similar en todos los años disponibles, excepto en 2019 y 2023, en los meses de Septiembre y Octubre en particular. Esto es un indicio de posibles outliers que requieran intervención.

---

```{r}
#| fig-align: center
ggseasonplot(diff_cantidad_clientes_ts) +
  labs(x = "Fecha", y = "Cantidad de \n       Personas", 
       title = "Serie de Cantidad de Personas con\n       Deuda en Santander",
       subtitle = "Primera Diferencia Regular",
       color = "Año") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  theme(panel.grid.minor = element_blank())
```

Separando los datos de acuerdo a los meses se desprende que los meses de Marzo, Junio, Septiembre y Diciembre presentan medias mayores en comparación al resto de los meses.

---

```{r}
ggsubseriesplot(diff_cantidad_clientes_ts) +
  labs(x = "Mes", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con
       Deuda en Santander",
       subtitle = "Primera Diferencia Regular") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

### FAC y FACP de la Serie Diferenciada

```{r}
#| fig-align: center

diff_clientes_acf <- ggAcf(diff_cantidad_clientes_ts, lag.max = 24, type = "correlation") +
      labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "FAC de la Serie Diferenciada") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

diff_clientes_pacf <- ggAcf(diff_cantidad_clientes_ts, lag.max = 24, type = "partial") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "FACP de la Serie Diferenciada") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

grid.arrange(diff_clientes_acf, diff_clientes_pacf)
```
Presencia de coeficientes significativos en los rezagos $3, \ 6, \ 9$, con una rápida aproximación a las bandas de confianza. Los coeficientes asociados a los rezagos $12$ y $24$ también resultan significativos, indicio de que la serie presente un componente estacional.

Las observaciones se encuentran autocorrelacionadas con sus valores de 3, 6 y 9 meses atrás.

### Dominio de Frecuencias: Análisis del Espectro de la Serie Diferenciada

```{r}
#| fig-align: center
Espectro_Serie_Diferenciada <- spectrum(diff_cantidad_clientes_ts, method = c("pgram"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = F) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Diferenciada_Tibble <- tibble(Frecuencias = Espectro_Serie_Diferenciada$freq*pi/max(Espectro_Serie_Diferenciada$freq),
                                Espectro = Espectro_Serie_Diferenciada$spec)
# Plot:
Plot_Espectro_Serie_Diferenciada <- ggplot(Espectro_Serie_Diferenciada_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma de la Serie Diferenciada)"),
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))

# Espectro de la Serie:
Espectro_Serie_Diferenciada <- spectrum(diff_cantidad_clientes_ts, method = c("ar"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = F) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Diferenciada_Tibble <- tibble(Frecuencias = Espectro_Serie_Diferenciada$freq*pi/max(Espectro_Serie_Diferenciada$freq),
                                Espectro = Espectro_Serie_Diferenciada$spec)
# Plot:
Plot_Espectro_Serie_Diferenciada_Suavizado <- ggplot(Espectro_Serie_Diferenciada_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma Suavizado de la Serie Diferenciada)"),
       subtitle = "Método: AR(3)",
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))

```

```{r}
Plot_Espectro_Serie_Diferenciada_Suavizado
```

La Primera Diferencia Regular elimina el componente tendencial, al presentar bajos valores en las frecuencias más bajas.

Se realza el peso de las frecuencias que se encuentran en torno a $\omega_{\max} = 2.10$ asociadas a ciclos de período $3$. Se incrementó la importancia de los ciclos que se repiten cada 3 meses a la hora de explicar la variabilidad de la serie. 

## Contrastes de Raíces Unitarias para la Segunda Diferencia Regular

```{r}
DF_Serie_Diferenciada <- ur.df(y = diff_cantidad_clientes_ts, type = "drift", selectlags = "BIC")
KPSS_Serie_Diferenciada <- ur.kpss(y = diff_cantidad_clientes_ts, type = "mu")
# DF rechaza Nula, no se tiene raíz unitaria.
# KPSS no se rechaza que sea I(0).
```


## Dickey-Fuller Aumentado

```{r}
# Tabla de estadísticos y valores críticos
df_results <- data.frame(
  "Estadístico" = DF_Serie_Diferenciada@teststat[1,],
  "VC 1%" = DF_Serie_Diferenciada@cval[,1],
  "VC 5%" = DF_Serie_Diferenciada@cval[,2],
  "VC 10%" = DF_Serie_Diferenciada@cval[,3]
)
rownames(df_results) <- c("tau2 (con constante)", "phi1")

kable(df_results, caption = "Resultados del Test de Dickey-Fuller Aumentado")
```

\

Se rechaza la Hipótesis Nula de que la serie presente una raíz unitaria en todos los niveles de significación planteados.

## KPSS

```{r}
kpss_results_df <- data.frame(
  Item = c("Estadístico de Test", "Valor Crítico 10%", "Valor Crítico 5%", "Valor Crítico 2.5%", "Valor Crítico 1%"),
  Valor = c(KPSS_Serie_Diferenciada@teststat, KPSS_Serie_Diferenciada@cval[1], KPSS_Serie_Diferenciada@cval[2], KPSS_Serie_Diferenciada@cval[3], KPSS_Serie_Diferenciada@cval[4])
)
kable(kpss_results_df, caption = "Resultados del Test KPSS (con constante)")
```

\

El no rechazo de la Hipótesis Nula de que la serie sea Integrada de Orden $0$, lo que nuevamente da un respaldo estadístico para continuar trabajando con la serie diferenciada, sin aplicar una Segunda Diferencia Regular ($d = 2$).

### Serie Diferenciada de acuerdo a Primera Diferencia Regular y Primera Diferencia Estacional

```{r}
diff_estacional_anual <- diff(diff_cantidad_clientes_ts, lag = 12)
```

```{r}
autoplot(diff_estacional_anual) +
  labs(x = "Fecha", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con 
       Deuda en Santander",
       subtitle = "Primera Diferencia Regular y Primera Diferencia Estacional (Anual)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

---

```{r}
#| fig-align: center
diff_estacional_anual_acf <- ggAcf(diff_estacional_anual, lag.max = 24, type = "correlation") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "FAC de la Serie Diferenciada (Regular y Estacional)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

diff_estacional_anual_pacf <- ggAcf(diff_estacional_anual, lag.max = 24, type = "partial") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "FACP de la Serie Diferenciada (Regular y Estacional)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

grid.arrange(diff_estacional_anual_acf, diff_estacional_anual_pacf)
```


Observar la FAC y FACP en los múltiplos de $12$. La significación tanto del primer coeficiente de autocorrelación como de autocorrelación parcial sugiere la utilización de $(P = 1, D = 1, Q = 0)$ o $(P = 0, D = 1, Q = 1)$ para la parte estacional de un primer modelo $\text{SARIMA}$.

---

```{r}
#| fig-align: center
# Espectro de la Serie:
Espectro_Serie_Diferenciada_Est_12 <- spectrum(diff_estacional_anual, method = c("pgram"), 
                                              freq = seq(from = 0, to = 0.5, length.out = 1000), plot = F) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Diferenciada_Tibble_12 <- tibble(Frecuencias = Espectro_Serie_Diferenciada_Est_12$freq*pi/max(Espectro_Serie_Diferenciada_Est_12$freq),
                                               Espectro = Espectro_Serie_Diferenciada_Est_12$spec)
# Plot:
Plot_Espectro_Serie_Diferenciada_12 <- ggplot(Espectro_Serie_Diferenciada_Tibble_12) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma de la Serie Diferenciada)"),
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))

Espectro_Serie_Diferenciada_Est_12 <- spec.ar(diff_estacional_anual, n.freq = 1000, #order = 1,
                                              plot = F)
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Diferenciada_Tibble_12 <- tibble(Frecuencias = Espectro_Serie_Diferenciada_Est_12$freq*pi/max(Espectro_Serie_Diferenciada_Est_12$freq),
                                               Espectro = Espectro_Serie_Diferenciada_Est_12$spec)
# Plot:
Plot_Espectro_Serie_Diferenciada_Suavizado_12 <- ggplot(Espectro_Serie_Diferenciada_Tibble_12) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma Suavizado de la Serie Diferenciada)"),
       subtitle = "Método: AR(0)",
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))

grid.arrange(Plot_Espectro_Serie_Diferenciada_12, Plot_Espectro_Serie_Diferenciada_Suavizado_12)  
```

La Primera Diferencia Regular en conjunto con la Primera Diferencia Estacional resultan en un Periodograma Suavizado semejante al de un Ruido Blanco. 

Observése el comportamiento del Periodograma Original, donde se alcanzan picos sucesivos en las frecuencias más altas, lo que está asociado a ciclos de período bajo.  

# Modelo Final Propuesto: SARIMA(2,1,0)(1,1,0)

```{r}
Modelo_Prueba_2 <- Arima(y = cantidad_clientes_ts,
                  order = c(3, 1, 0),
                  #seasonal = list(order = c(0,1,1), period = 12),
                  fixed = c(
                    0, 0, NA
                  ),
                  method = "ML")
#tbl_regression(Modelo_Prueba_2, exponentiate = FALSE, tidy_fun = tidy_arima) |>
#  add_significance_stars(hide_ci = FALSE, hide_p = FALSE) |>
#  modify_caption("Coeficientes del Modelo SARIMA(3,1,0)(0,0,0)")

model_m2_initial_metrics <- data.frame(
  AIC = Modelo_Prueba_2$aic,
  AICc = Modelo_Prueba_2$aicc,
  BIC = Modelo_Prueba_2$bic
)
#kable(model_m2_initial_metrics, caption = "Criterios de Información del Modelo Inicial")
```

## Outliers

\

Se partió de un Modelo $\text{SARIMA}(3,1,0)(0,0,0)$ con $\phi_1 = \phi_2 = 0$ en base al análisis anterior.

Los residuos estandarizados indicaron la presencia de outliers. A su vez, se rechazó la Hipótesis Nula de Normalidad en los contrastes de Shapiro-Wilk y Jarque-Bera, lo que motivó la intervención de los siguientes puntos anómalos:

- Outlier Aditivo en Setiembre de 2019.

- Cambio Transitorio en Diciembre de 2019.

- Cambio Transitorio en Diciembre de 2021.

- Outlier Aditivo en Febrero de 2023.

- Outlier Aditivo en Agosto de 2023.

- Cambio Transitorio en Octubre de 2023.

- Cambio Transitorio en Junio de 2024.

```{r}
# Detección de atípicos en un modelo base
outlier_m2_detect <- tso(cantidad_clientes_ts, 
                  cval = 2.5, 
                  types = c("AO", "LS", "TC"), 
                  tsmethod = "arima", 
                  args.tsmethod = list(order = c(2, 1, 0),
                                       seasonal = list(order = c(1,1,0), period = 12),
                                       include.mean= FALSE))

# Creación de regresores para atípicos
AO_2019_09_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 10), length(cantidad_clientes_ts))
TC_2019_12_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 13), length(cantidad_clientes_ts))
TC_2021_12_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 37), length(cantidad_clientes_ts))
AO_2023_02_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 51), length(cantidad_clientes_ts))
AO_2023_08_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 57), length(cantidad_clientes_ts))
TC_2023_10_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 59), length(cantidad_clientes_ts))
TC_2024_06_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 67), length(cantidad_clientes_ts)) 

xreg_m2 <- cbind(AO_2019_09_m2, TC_2019_12_m2, TC_2021_12_m2, AO_2023_02_m2, AO_2023_08_m2, TC_2023_10_m2, TC_2024_06_m2)
```


## Ajuste del Modelo Final

```{r}
modelo_2 <- Arima(y = cantidad_clientes_ts,
                  order = c(2, 1, 0),
                  seasonal = list(order = c(1,1,0), period = 12),
                  fixed = c(0, NA, NA, NA, NA, NA, NA, NA, NA, NA),
                  xreg = xreg_m2,
                  method = "ML")
                
```

```{r}
tbl_regression(modelo_2, exponentiate = FALSE, tidy_fun = tidy_arima) |>
  add_significance_stars(hide_ci = FALSE, hide_p = FALSE) |>
  modify_caption("Coeficientes del Modelo SARIMA(2,1,0)(1,1,0)")
```




### Criterios de Información y Medidas de Error

\

```{r}
model_m2_metrics <- data.frame(
  AIC = modelo_2$aic,
  AICc = modelo_2$aicc,
  BIC = modelo_2$bic
)

kable(model_m2_initial_metrics, caption = "Criterios de Información del Modelo SARIMA(3,1,0)(0,0,0)")
```

\

```{r}
kable(model_m2_metrics, caption = "Criterios de Información del Modelo SARIMA(2,1,0)(1,1,0)")
```

\

```{r}
error_measures_m2 <- accuracy(modelo_2) %>% as.data.frame()
kable(error_measures_m2, caption = "Medidas de Error del Modelo SARIMA(2,1,0)(1,1,0)")
```


### Diagnóstico de Residuos

```{r}
#| fig-align: center
residuos_m2 <- residuals(modelo_2)
autoplot(residuos_m2) +
  labs(x = "Fecha", y = "Residuos", title = "Residuos del Modelo SARIMA(2,1,0)(1,1,0)") +
  geom_hline(yintercept = 0, color = "red") +
  theme_minimal()

```

---

```{r}
residuos_m2_acf <- ggAcf(residuos_m2, lag.max = 24, type = "correlation") +
  labs(title = "FAC de los Residuos del Modelo SARIMA(2,1,0)(1,1,0)") +
  theme_minimal()
residuos_m2_pacf <- ggAcf(residuos_m2, lag.max = 24, type = "partial") +
  labs(title = "FACP de los Residuos del Modelo SARIMA(2,1,0)(1,1,0)") +
  theme_minimal()

grid.arrange(residuos_m2_acf, residuos_m2_pacf)
```

Buen comportamiento de los residuos. No hay coeficientes de autocorrelación ni autocorrelación parcial que resulten significativos.

## Test de Ljung-Box

\

```{r}
ljung_box_df_m2 <- tibble()
for(i in c(3, 6, 9, 12,24)){
  ljung_box_df_m2 <- rbind(ljung_box_df_m2, (Box.test(
    residuos_m2, lag = i, type = "Ljung-Box", fitdf = 3) %>% tidy())) # 2 + 1, Regular + Estacional
}
kable(ljung_box_df_m2, caption = "Test de Ljung-Box para Residuos del Modelo SARIMA(2,1,0)(1,1,0) (Rezagos 3, 6, 9, 12 y 24)")
```

\

Los p-valores asociados al contraste de Ljung-Box son particularmente bajos. Esta modelización puede estar incumpliendo el supuesto de residuos no autocorrelacionados.

## Análisis de Normalidad

```{r}
# Residuos estandarizados
residuos_estandarizados_m2 <- residuos_m2 / sqrt(modelo_2$sigma2)
autoplot(residuos_estandarizados_m2) +
  labs(x = "Año", y = "Residuos Estandarizados", title = "Residuos Estandarizados del Modelo SARIMA(2,1,0)(1,1,0)") +
  geom_hline(yintercept = 3, color = "red") +
  geom_hline(yintercept = -3, color = "red") +
  theme_minimal()


```

---

```{r}
ggplot(data.frame(residuos = residuos_m2), aes(sample = residuos)) +
  stat_qq() + stat_qq_line(color = "red") +
  labs(title = "QQ-plot de Residuos del Modelo SARIMA(2,1,0)(1,1,0)") +
  theme_minimal()
```

## Contrastes de Normalidad

```{r}
shapiro_test_m2 <- shapiro.test(residuos_m2) |> tidy()
jarque_bera_test_m2 <- jarque.bera.test(residuos_m2) |> tidy()
normalidad_m2 <- dplyr::bind_rows(
  "Shapiro-Wilk" = shapiro_test_m2,
  "Jarque-Bera" = jarque_bera_test_m2,
  .id = "Test"
)
kable(normalidad_m2, caption = "Tests de Normalidad para Residuos del Modelo SARIMA(2,1,0)(1,1,0)")
```

\

Los Contrastes de Normalidad resultan en el no rechazo de la correspondiente Hipótesis Nula, por lo que no se dispone de evidencia estadísticamente significativa de que los residuos no se distribuyan de acuerdo a una Distribución Gaussiana.

## Homocedasticidad

```{r}
residuos_m2_sq <- residuos_m2^2
residuos_sq_acf_m2 <- ggAcf(residuos_m2_sq, lag.max=24, type = "correlation") + labs(title = "FAC del Cuadrado de los Residuos del Modelo SARIMA(2,1,0)(1,1,0)") + theme_minimal()
residuos_sq_pacf_m2 <- ggAcf(residuos_m2_sq, lag.max=24, type = "partial") + labs(title = "FACP del Cuadrado de los Residuos del Modelo SARIMA(2,1,0)(1,1,0)")  + theme_minimal()
grid.arrange(residuos_sq_acf_m2, residuos_sq_pacf_m2)

# Ljung-Box para los Cuadrados de los Residuos.
ljung_box_df_m2_residuos_cuadrado <- tibble()
for(i in c(3, 6, 9, 12, 24)){
  ljung_box_df_m2_residuos_cuadrado <- rbind(
    ljung_box_df_m2_residuos_cuadrado, 
    (Box.test(residuos_m2_sq, 
              lag = i, type = "Ljung-Box", fitdf = 3) %>% tidy()))
};rm(i)
```

La significación de los coeficientes de autocorrelación y autocorrelación parcial de orden 6 sugiere el posible incumplimiento del supuesto de homocedasticidad.

## Test de Ljung-Box

```{r}
kable(ljung_box_df_m2_residuos_cuadrado, caption = "Test de Ljung-Box para el Cuadrado de los Residuos del Modelo SARIMA(2,1,0)(1,1,0) (Rezagos 3, 6, 9, 12 y 24)")
```

\

Los resultados del contraste de Ljung-Box respaldan esta idea, si se considera los rezagos más pequeños.



## Contraste de Media Nula de los Residuos

```{r}
Media_Testear <- mean(residuos_m2)/(sd(residuos_m2)/sqrt(73))
Resultado_Prueba_t <- (t.test(residuos_m2, mu = 0) %>% tidy)[,1:4]
kable(Resultado_Prueba_t, caption = "Tests de Media Nula para Residuos del Modelo SARIMA(2,1,0)(1,1,0)")
```

\

No se rechaza la Hipótesis Nula de que los residuos tengan una media distinta de $0$.

# Predicción

El Modelo a utilizar es un $\text{SARIMA}(2,1,0)(1,1,0)$ con $\phi_1 = 0$, que puede expresarse como:

$$
(1-L)(1-L^{12})(1-L^2{\phi}_2)(1-L{\Phi}_1)Y_t = \epsilon_t
$$

Donde $Y_t$ denota a la serie de datos original, $L$ al operador de rezagos y $\epsilon_t$ un ruido blanco. 

${\phi}_2$ y ${\Phi}_1$ son los coeficientes respectivos de las partes AR del componente regular y estacional del Modelo.

## Enero, Febrero y Marzo de 2025

Se realiza predicciones para los meses de Enero, Febrero y Marzo de 2025, a efectos de contrastarla con las tres observaciones que no se utilizaron a la hora de ajustar el Modelo.

```{r}
# Crear matriz de regresores futuros, ceros en caso de AO, pero en caso de TS que continuen el decaimiento.
# Predicciones a 12 pasos:
xreg_prediccion_m2 <- tibble(
  AO10 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 10), length(cantidad_clientes_ts) + 12),
  TC13 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 13), length(cantidad_clientes_ts) + 12),
  TC37 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 37), length(cantidad_clientes_ts) + 12),
  AO51 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 51), length(cantidad_clientes_ts) + 12),
  AO57 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 57), length(cantidad_clientes_ts) + 12),   
  TC59 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 59), length(cantidad_clientes_ts) + 12),
  TC67 = tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 67), length(cantidad_clientes_ts) + 12)
)

Predicciones_Modelo_2 <- forecast(
  modelo_2, fan = TRUE, xreg = as.matrix(xreg_prediccion_m2[74:85,]), h = 12)

autoplot(object = Predicciones_Modelo_2) +
  labs(title = "Cantidad de Clientes con Deuda en Santander: 
       Predicción de 2025",
       subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
       x = "Fecha", y = "") +
  theme_minimal()

Comparacion_Prediccion_Realidad_Modelo_2 <- tibble(
  Fecha = (time(cantidad_clientes_ts_completa) %>% as.Date())[(length(cantidad_clientes_ts_completa)-2):length(cantidad_clientes_ts_completa)],
  Predicción = Predicciones_Modelo_2$mean[1:3],
  Realidad = cantidad_clientes_ts_completa[(length(cantidad_clientes_ts_completa)-2):length(cantidad_clientes_ts_completa)]) %>%
  pivot_longer(cols = c(Predicción, Realidad),
               names_to = "Serie",
               values_to = "Valores")

```

---

```{r}
#| fig-align: center

ggplot(Comparacion_Prediccion_Realidad_Modelo_2) +
  geom_line(aes(x = Fecha, y = Valores, color = Serie)) +
  theme_minimal() +
  labs(
    title = "Cantidad de Clientes con Deuda en Santander: 
    Predicción contra Realidad",
    subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
    y = "",
    x = "Fecha",
    color = ""
  ) +
  guides(color = guide_legend(position = "bottom")) 
```


Se predice que la Cantidad de Clientes con Deuda Vigente en el Banco Santander aumentará, respecto al mes de Diciembre de 2024, en un 0.21%, 0.22% y 1.53% para los meses de Enero, Febrero y Marzo de 2025, respectivamente. En la realidad, dichas variaciones porcentuales fueron de 0.27%, 1,90% y 1.81% respectivamente, lo que comienza a evidenciar una característica que se repetirá durante el siguiente análisis: la subestimación a la hora de predecir por parte del Modelo planteado.

### Inrtervalos de Predicción


```{r}
Predicciones_Modelo_2_Tabla_ICs <- forecast(
  modelo_2, fan = FALSE, xreg = as.matrix(xreg_prediccion_m2[74:85,]), h = 12,
  level = c(50, 75, 90, 96))

Tabla_ICs_1 <- (Predicciones_Modelo_2_Tabla_ICs %>% as.tibble %>% janitor::clean_names())[1:3,] %>% 
  select(lo_50, hi_50) %>% 
  cbind(
    tibble(
  Fecha = c("Enero - 2025", "Febrero - 2025", "Marzo - 2025"),
  Prediccion = Predicciones_Modelo_2_Tabla_ICs$mean[1:3],
  Realidad = cantidad_clientes_ts_completa[(length(cantidad_clientes_ts_completa)-2):length(cantidad_clientes_ts_completa)])
  ) %>% 
  mutate(Capturado = ifelse((lo_50 <= Realidad)&(hi_50 >= Realidad), "Si", "No")) %>% 
  select(Fecha, `Límite Inferior 50%` = lo_50, Predicción = Prediccion, `Límite Superior 50%` = hi_50, Realidad, Capturado)

kable(Tabla_ICs_1, caption = "Intervalos de Predicción al 50% de los Primeros 3 Meses de 2025 contra Realidad")

```

\

```{r}

Tabla_ICs_4 <- (Predicciones_Modelo_2_Tabla_ICs %>% as.tibble %>% janitor::clean_names())[1:3,] %>% 
  select(lo_96, hi_96) %>% 
  cbind(
    tibble(
  Fecha = c("Enero - 2025", "Febrero - 2025", "Marzo - 2025"),
  Prediccion = Predicciones_Modelo_2$mean[1:3],
  Realidad = cantidad_clientes_ts_completa[(length(cantidad_clientes_ts_completa)-2):length(cantidad_clientes_ts_completa)])
  ) %>% 
  mutate(Capturado = ifelse((lo_96 <= Realidad)&(hi_96 >= Realidad), "Si", "No")) %>% 
  select(Fecha, `Límite Inferior 96%` = lo_96, Predicción = Prediccion, `Límite Superior 96%` = hi_96, Realidad, Capturado)

kable(Tabla_ICs_4, caption = "Intervalos de Predicción al 96% de los Primeros 3 Meses de 2025 contra Realidad")
```

## Resultados

Se puede apreciar que se captura al 50% de confianza el valor real de la serie en los meses de Enero y Marzo de 2025. Sin embargo, el valor de Febrero de 2025 requiere utilizar un intervalo de amplitud mayor asociado a una confianza aproximada del 96%.

## Métricas sobre los errores de predicción

\

```{r}
test_clientes <- window(cantidad_clientes_ts_completa, start = c(2025,1))
acc1 <- round(accuracy(Predicciones_Modelo_2, test_clientes), 4)
kable(acc1, caption = r"(Métricas de Predicción - SARIMA$(2,1,0)(1,1,0)$)") 
```


## 2024 y 2025

También se realiza predicciones para el 2024 y los primeros tres meses de 2025, utilizando el mismo modelo propuesto pero entrenándolo con las observaciones disponibles hasta Diciembre de 2023.

```{r}
#| fig-align: center

# Predicción afuera de la Muestra:
# Muestra de entrenamiento ("training set") hasta 2022 inclusive
train_clientes <- window(cantidad_clientes_ts_completa, end = c(2023,12))
# length(train_clientes)

# Dejamos los datos de 2023 como conjunto de prueba ("test set")
test_clientes <- window(cantidad_clientes_ts_completa, start = 2024)
n <- length(test_clientes)

# Modelo 2 Entrenado hasta 2023.
Modelo_Final_train_m2 <- Arima(y = train_clientes,
                        order = c(2, 1, 0),
                        seasonal = list(order = c(1,1,0), period = 12),
                        fixed = c(
                          0, NA,
                          NA,
                          NA, NA, NA, NA, NA, NA #, NA
                          ), # Un outlier vendría después.
                        xreg = xreg_m2[1:61,1:6],
                        method = "ML")

# Predicción fuera de la muestra:
Pred_Final_Test_m2 <- forecast(Modelo_Final_train_m2, h = n, 
                        xreg = as.matrix(xreg_prediccion_m2[62:(dim(xreg_prediccion_m2)[1] -9),1:6]))
# accuracy(Pred_Final_Test_m2, test_clientes)

autoplot(object = Pred_Final_Test_m2) +
  labs(title = "Cantidad de Clientes con Deuda en Santander: 
       Predicción de 2024 y Principios 2025",
       subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
       x = "Fecha", y = "") +
  theme_minimal()

```

---

```{r}
Predicciones_Dentro_Muestra_Tibble_m2 <- tibble(
  Fecha = Pred_Final_Test_m2$mean %>% time %>% as.Date(),
  Predicción = Pred_Final_Test_m2$mean[1:length(Pred_Final_Test_m2$mean %>% time %>% as.Date())],
  Realidad = cantidad_clientes_ts_completa[
    (length(cantidad_clientes_ts_completa)-(
      length(Pred_Final_Test_m2$mean %>% time %>% as.Date())-1)):length(cantidad_clientes_ts_completa)]) %>%
  pivot_longer(cols = c(Predicción, Realidad),
               names_to = "Serie",
               values_to = "Valores")

ggplot(Predicciones_Dentro_Muestra_Tibble_m2) +
  geom_line(aes(x = Fecha, y = Valores, color = Serie)) +
  theme_minimal() +
  labs(
    title = "Cantidad de Clientes con Deuda en Santander: 
    Predicciones dentro de Muestra",
    subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
    y = "",
    x = "Fecha",
    color = ""
  ) +
  guides(color = guide_legend(position = "bottom")) 
```


Se nota una diferencia en la pendiente de la predicción puntual y la realidad. La primera tiende a ser cada vez menor que la segunda a medida que aumenta el horizonte de predicción. 

## Métricas sobre los errores de predicción

\

```{r}
acc2 <- round(accuracy(Pred_Final_Test_m2, test_clientes), 4)
kable(acc2, caption = r"(Métricas de Predicción - SARIMA$(2,1,0)(1,1,0)$)") 
```

## A partir de Junio de 2024

Considerando una muestra de entrenamiento con límite en Junio de 2024, tal que se incorpore el cambio transitorio identificado para ese mes.

```{r}
# Si se lograra capturar el atípico, es decir, darse cuenta que en
# Junio de 2024 ocurrió un cambio transitorio.
train_clientes <- window(cantidad_clientes_ts_completa, end = c(2024,6))
# length(train_clientes)

# Dejamos los datos de 2023 como conjunto de prueba ("test set")
test_clientes <- window(cantidad_clientes_ts_completa, start = c(2024,7))
n <- length(test_clientes)

# Modelo 3
Modelo_Final_train_m2_2 <- Arima(y = train_clientes,
                            order = c(2, 1, 0),
                            seasonal = list(order = c(1,1,0), period = 12),
                            fixed = c(
                              0, NA,
                              NA,
                              NA, NA, NA, NA, NA, NA, NA
                            ), # Un outlier vendría después.
                            xreg = xreg_m2[1:67,],
                            method = "ML")
Pred_Final_Test_m2_2 <- forecast(Modelo_Final_train_m2_2, h = n, 
                            xreg = as.matrix(xreg_prediccion_m2[68:(dim(xreg_prediccion_m2)[1]),]))
# accuracy(Pred_Final_Test_m2_2, test_clientes)

autoplot(object = Pred_Final_Test_m2_2) +
  labs(title = "Cantidad de Clientes con Deuda en Santander: 
       Predicción a partir de Junio de 2024",
       subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
       x = "Fecha", y = "") +
  theme_minimal()

```

---

```{r}
Predicciones_Dentro_Muestra_Tibble_m2_2 <- tibble(
  Fecha = (Pred_Final_Test_m2_2$mean %>% time %>% as.Date())[1:9],
  Predicción = Pred_Final_Test_m2_2$mean[1:9],
  Realidad = cantidad_clientes_ts_completa[
    (length(cantidad_clientes_ts_completa)-(8)):length(cantidad_clientes_ts_completa)]) %>%
  pivot_longer(cols = c(Predicción, Realidad),
               names_to = "Serie",
               values_to = "Valores")

ggplot(Predicciones_Dentro_Muestra_Tibble_m2_2) +
  geom_line(aes(x = Fecha, y = Valores, color = Serie)) +
  labs(
    title = "Cantidad de Clientes con Deuda en Santander: 
    Predicciones dentro de Muestra",
    subtitle = TeX(r"(Modelo SARIMA$(2,1,0)(1,1,0)$)"),
    y = "",
    x = "Fecha",
    color = ""
  ) +
  theme_minimal() +
  guides(color = guide_legend(position = "bottom")) 
```

La predicción para los siguientes meses resulta bastante precisa. Es solo a partir de Diciembre del 2024 que se observa una discrepancia relativamente mayor con la serie empírica con tendencia a subestimar.

## Métricas sobre los errores de predicción

\

```{r}
acc3 <- round(accuracy(Pred_Final_Test_m2_2, test_clientes), 4)
kable(acc3, caption = r"(Métricas de Predicción - SARIMA$(2,1,0)(1,1,0)$)") 
```

# Descomposición de la Serie

\

Mediante la función `x13` (asociada al método estadístico del mismo nombre) del paquete `RJDemetra` se llevó acabo la descomposición de la serie (de acuerdo a términos aditivos), tomando en cuenta el Modelo Final planteado anteriormente.

Como resultado se obtuvo la descomposición de la serie, lo que permitió computar una serie desestacionalizada.

## Resultados

```{r}
load("./data/Salidas_Script_Componentes.Rdata")
grid.arrange(Plot_1_Serie_Original, Plot_2_Serie_Desestacionalizada, Plot_4_SA_T, nrow = 3)
```

## Resultados

En los dos primeros gráficos se puede notar como la serie se ha vuelto más suave, no reflejando las periodicidades de la serie original. 

En el tercer gráfico se compara la serie desestacionalizada con el componente tendencial, siendo posible identificar los apartamientos de la tendencia debido a los outliers destacados previamente.

### Componente estacional

```{r}
#| fig-align: center

Plot_5_Estacional
```

El componente estacional se comporta de forma esperable, presentando, en general, picos de altura similar cada 12 meses.  

A su vez, los picos ocurren, en general, con una frecuencia trimestral, lo que va de la mano con el hecho de que en los meses de Marzo y Septiembre incluyan períodos vacacionales que incentivan la solicitud de créditos mientras que en Junio y Diciembre aumente en el número de deudores debido a el pasaje de deudas no vigentes a vigentes.

### Componente irregular

```{r}
#| fig-align: center

Plot_6_Irregular
```

El componente irregular refleja en su comportamiento la inclusión de los outliers, que fueron de tipo aditivo y de cambio transitorio.


---

A las predicciones realizadas en el punto anterior, se le agrega las predicciones de los componentes tendencial así como de la serie desestacionalizada:

```{r}
#| fig-align: center

grid.arrange(Plot_8_Prediccion_Serie_Desestacionalizada, Plot_9_Componente_Tendencia, nrow = 2)
```

Se espera, entonces, que la tendencia de la Cantidad de Clientes con Deuda en el Banco Santander continúe aumentando en el tiempo, más allá de la estacionalidad que caracteriza a la serie.

# Comentarios Finales

\

Respecto al Modelo $\text{SARIMA}(2,1,0)(1,1,0)$ se debe tener en cuenta que:

- Se logra el no rechazo de los Contrastes de Normalidad utilizando siete intervenciones por atípicos, lo que dada la baja cantidad de observaciones disponibles puede resultar un número no deseable.

- El supuesto de residuos no autocorrelacionados puede no estar cumpliéndose, tal y como se refleja en los p-valores del Contraste de Ljung-Box, que resultan cercanos al 5%.

- Dadas dos muestras de entrenamiento se observó la tendencia a subestimar por parte del modelo.

---

\

\

No obstante lo anterior, esta modelización presenta los siguientes puntos a destacar:

- El Modelo $\text{SARIMA}$ resultante es de bajo orden, lo que va de la mano con la idea de que los modelos de este tipo sean los mejores a la hora de predecir, además de resultar más parsimoniosos. 

- Si bien se tiene indicios de que puede no estar cumpliéndose el supuesto de homocedasticidad, la transformación logarítmica no logra homogeneizar la Varianza de la serie, por lo que se se descarta la aplicación de dicha transformación.

- Se logra predecir con éxito a un bajo nivel de confianza dos de tres valores que tomó la serie en 2025: los asociados a los meses de Enero y Marzo. En el caso de Febrero se subpredice el valor que toma efectivamente la serie.

- Ensayando el Modelo sugerido por `x13` ($\text{SARIMA}(0,1,0)(1,0,1)$) también se observa la tendencia a subestimar a la hora de predecir, con el detalle de que en este se hace de forma más notoria que el Modelo Original, evidenciado por los valores más altos en las métricas ME, MAE, MPE y MAPE.

# ¿Preguntas?

# Gracias!!!
