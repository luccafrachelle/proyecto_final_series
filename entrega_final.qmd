---
title: "Entrega Final - Series Cronológicas"
subtitle: "Facultad de Ciencias Económicas y Administración - 2025 - UDeLaR"
author: "Leandro Berrueta, Lucca Frachelle, Cecilia Waksman"
date: today
warning: false
message: false
echo: false
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme:
      light: flatly
      dark: darkly
    fig-align: center
    toc-float: true
embed-resources: true
toc-location: right
toc-title: 'Contenido'
---

```{r}
# Paquetes:
library(forecast)
library(tidyverse)
library(tseries)
library(forecast)
library(urca)
library(lmtest)
library(gridExtra)
library(seasonal)
library(readxl)
library(knitr)
library(kableExtra)
library(broom)
library(tseries)
library(gtsummary)
library(latex2exp) # Permite usar TeX() para incluir elementos LaTeX en ggplots.
library(tsoutliers) # Permite chequear outliers mediante funciones.
```

```{r}
df <- read_excel("series_bcu.xlsx" , sheet = "cantidad_personas_deuda_vigente") %>%
  select(fecha, cantidad_clientes, tipoinstitucion) %>%
  filter(tipoinstitucion == "Santander")
cantidad_clientes_ts <- ts(df$cantidad_clientes, start = c(2018, 12), end = c(2024, 12), frequency = 12)
cantidad_clientes_ts_completa <- ts(df$cantidad_clientes, start = c(2018, 12), frequency = 12) 
# Se deja 3 observaciones para predicción
```

Se dispone de una serie mensual con la cantidad de clientes con deuda vigente en el Banco Santander en el período Diciembre - 2018 a Marzo - 2025. 

Se utiliza como entrenamiento los datos hasta 2024, y luego para predecir las 3 observaciones referidas a 2025.

Una primera visualización de la serie permite identificar una clara tendencia creciente a lo largo del tiempo, especialmente a partir de 2020, con un aumento significativo hacia 2024. 

En principio no se logra reconocer un comportamiento estacional evidente o un patrón repetitivo a intervalos fijos en la serie. 

La variabilidad parece aumentar ligeramente con el nivel de la serie, lo que podría sugerir la necesidad de aplicar una transformación logarítmica a modo de homogeneizar la Varianza de la serie. El uso de dicha transformación se evaluará más adelante tomando como insumo el comportamiento de los residuos.




# Análisis Inicial

## Gráfico de la Serie Temporal


```{r}
autoplot(cantidad_clientes_ts_completa) + 
  labs(x = "Fecha", y = "Cantidad 
       de personas", title = "Serie de Cantidad de Personas con Deuda en Santander") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank()) 

```


```{r}
## series log
cantidad_clientes_ts_log <- log(cantidad_clientes_ts)
autoplot(log(cantidad_clientes_ts_completa)) + 
  labs(x = "Fecha", y = TeX(r"($\log($Cantidad$)$)"), title = "Serie del Logaritmo de la Cantidad de Personas
       con Deuda en Santander") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

```

## Estadísticas Descriptivas
```{r}
cantidad_clientes_ts %>%  
  summary() %>%  
  enframe(name = "Estadística", value = "Valor") |> 
  kable(caption = "Estadísticas Descriptivas de la Serie de Cantidad de Personas con Deuda") 
```

# Identificación del Modelo

## Análisis en el Dominio del Tiempo

### Función de Autocorrelación (FAC)
```{r}
clientes_acf <- ggAcf(cantidad_clientes_ts, lag.max = 24, type = "correlation") + 
  labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "Función de Autocorrelación (FAC)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

clientes_acf
```

Se observa que la Función de Aucorrelación (FAC) decrece lentamente y de forma persistente, con coeficientes de autocorrelación significativos que se mantienen altos incluso en rezagos grandes y que, por ende, no se comportan de acuerdo al decaimiento exponencial que caracteriza a las series débilmente estacionarias^[En el presente trabajo se utilizará como sinónimos "estacionariedad en sentido débil", "estacionariedad en covarianza" y "estacionariedad", al igual que se hizo durante el desarrollo del curso.]. Esto es un fuerte indicio de que la serie no es estacionaria. 

Además, las autocorrelaciones significativas en rezagos altos sugieren la presencia de una tendencia, detalle claramente observable al inspeccionar el gráfico de la serie.

### Función de Autocorrelación Parcial (FACP)
```{r}
clientes_pacf <- ggAcf(cantidad_clientes_ts, lag.max = 24, type = "partial") + 
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "Función de Autocorrelación Parcial (FACP)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

clientes_pacf
```

La Función de Aucorrelación Parcial (FACP) muestra un coeficiente significativo en el primer rezago y luego decae rápidamente, no habiendo otro rezago que resulte significativo al nivel de significación usual del 5%. 

Esto podría sugerir un componente AR(1) si la serie fuera estacionaria. Sin embargo, dada la FAC planteada anteriormente, se concluye de este primer análisis del Dominio del Tiempo en la necesidad de aplicar, al menos, una primera diferencia regular a la serie.

## Análisis en el Dominio de Frecuencias

```{r}
# Espectro de la Serie:
Espectro_Serie <- spectrum(cantidad_clientes_ts, method = c("ar"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = FALSE) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Tibble <- tibble(Frecuencias = Espectro_Serie$freq*pi/max(Espectro_Serie$freq),
                                Espectro = Espectro_Serie$spec)
# Plot:
Plot_Espectro_Suavizado <- ggplot(Espectro_Serie_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma Suavizado de la Serie)"),
       subtitle = "Método: AR(1)",
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))
Plot_Espectro_Suavizado  
```

Mediante el Periodograma Suavizado de la serie es posible respaldar la idea de que la misma presenta una tendencia que debería ser modelada. 

En particular, las frecuencias más próximas a 0, y por ende las asociadas a ciclos de período próximo a infinito (el componente tendencial) explica la mayor parte de la variabilidad de la serie^[Corresponde resaltar, sin embargo, que la relación entre el área que se encuentra por debajo del Espectro/Periodograma y la Varianza de la serie se plantea para series estacionarias, propiedad que claramente no caracteriza a la serie en tratamiento.].

## Contraste de Raíces Unitarias

A la hora de determinar si la tendencia puede ser modelada de forma determinística o si la misma es resultado de la presencia de raíces unitarias se lleva acabo los Contrastes de Dickey-Fuller aumentado y KPSS.

### Dickey-Fuller

En primera instancia se plantea el contraste seleccionando la cantidad de lags por medio de Criterios de Información (AIC y BIC) lo que resulta en la elección de $p = 1$. Con este valor, sin embargo, no se logra el comportamiento deseado de los residuos (que los mismos sean autocorrelacionados), por lo que se procedió a probar con varios valores de lags adicionales. Esto resultó en la elección de $p = 2$, con ambos coeficientes significativos a los niveles de significación usuales.

```{r}
DF_Serie_Original <- ur.df(y = cantidad_clientes_ts, type = "trend", lags = 2)
plot(DF_Serie_Original)
```

A continuación se presentan los resultados de la regresión auxiliar del test y los estadísticos de prueba.

```{r}
# Tabla de regresión del test
DF_Serie_Original@testreg |>
  tbl_regression(intercept = TRUE) |>
  modify_caption("Regresión del Test de Dickey-Fuller Aumentado")
```

```{r}
# Tabla de estadísticos y valores críticos
df_results <- data.frame(
  "Estadístico" = DF_Serie_Original@teststat[1,],
  "VC 1%" = DF_Serie_Original@cval[,1],
  "VC 5%" = DF_Serie_Original@cval[,2],
  "VC 10%" = DF_Serie_Original@cval[,3]
)
rownames(df_results) <- c("tau3 (con tendencia)", "phi2", "phi3")

kable(df_results, caption = "Resultados del Test de Dickey-Fuller Aumentado")
```

Del contraste de Dickey-Fuller aumentado se concluye que:

- No se rechaza la Hipótesis Nula de que la Serie presente una raíz unitaria a ninguno de los niveles de significación planteados. De esta manera se tiene un respaldo para aplicar la Primera Diferencia Regular.

- PREGUNTAR (en base a phi3): Se rechaza la Hipótesis Nula de que $b = 0, \gamma = 0$. Es decir, no hay raiz unitaria presente ni término de tendencia determinístico. Considerando el punto anterior esto sugiere que la serie no presenta una tendencia determinística que deba ser modelada.

- PREGUNTAR (en base a phi2): No se rechaza la Hipótesis Nula de que $a = 0 , b = 0, \gamma = 0$.

### KPSS

En segunda instancia se plantea el Contraste KPSS, lo que resulta en que 

```{r}
KPSS_Serie_Original <- ur.kpss(y = cantidad_clientes_ts, type = "tau")

kpss_results_df <- data.frame(
  Item = c("Estadístico de Test", "Valor Crítico 10%", "Valor Crítico 5%", "Valor Crítico 2.5%", "Valor Crítico 1%"),
  Valor = c(KPSS_Serie_Original@teststat, KPSS_Serie_Original@cval[1], KPSS_Serie_Original@cval[2], KPSS_Serie_Original@cval[3], KPSS_Serie_Original@cval[4])
)
kable(kpss_results_df, caption = "Resultados del Test KPSS (con tendencia)")
```

Como resultado se rechaza la Hipótesis Nula de que la Serie sea Integrada de Orden 0, lo que nuevamente da un respaldo para la Aplicación de la Primera Diferencia Regular en los datos.

## Serie Diferenciada de acuerdo a la Primera Diferencia Regular
```{r}
diff_cantidad_clientes_ts <- diff(cantidad_clientes_ts, differences = 1)
autoplot(diff_cantidad_clientes_ts) + 
  labs(x = "Fecha", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con Deuda en Santander",
       subtitle = "Primera Diferencia Regular") +
  geom_hline(aes(yintercept = mean(diff_cantidad_clientes_ts)), colour = "red") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

La primera diferencia regular tiene como resultado una serie que adquiere un comportamiento más próximo al estacionario que la serie original. En principio es posible observar que la tendencia ha sido eliminada y la Media parece ser constante. No obstante, la Varianza no se comporta de forma constante.

```{r}
ggseasonplot(diff_cantidad_clientes_ts) +
  labs(x = "Fecha", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con Deuda en Santander",
       subtitle = "Primera Diferencia Regular") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

```{r}
ggsubseriesplot(diff_cantidad_clientes_ts)
```

En el primer gráfico se puede observar que la serie se comporta de forma similar en todos los años disponibles, con la excepción de los años 2019 y 2024, en los meses de setiembre y octubre en particular. Esto puede ser un indicio de un posible outlier que requiera intervención.

Del segundo gráfico se destaca los meses de marzo, junio, septiembre y diciembre, que presentan medias mayores en comparación al resto.

## FAC y FACP de la Serie Diferenciada
```{r}
diff_clientes_acf <- ggAcf(diff_cantidad_clientes_ts, lag.max = 24, type = "correlation") +
      labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "FAC de la Serie Diferenciada") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

diff_clientes_pacf <- ggAcf(diff_cantidad_clientes_ts, lag.max = 24, type = "partial") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "FACP de la Serie Diferenciada") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

grid.arrange(diff_clientes_acf, diff_clientes_pacf)
```

Al analizar la Función de Autocorrelación de la serie de Cantidad de Personas con Deuda en Santander una vez aplicada la Primera Diferencia Regular ($d=1$), se observa que, aunque la tendencia lineal ha sido eliminada (lo que se corrobora con los tests de Dickey-Fuller Aumentado y KPSS), persisten patrones de Autocorrelación significativos.

Específicamente, se nota la presencia de coeficientes significativos en el rezago 3, en el rezago 6 y en el rezago 9, con una rápida aproximación a las bandas de confianza^[El coeficiente asociado al rezago 12 también es significativo, aunque como su magnitud es mayor a la del coeficiente del rezago 9 se decide, en principio, trabajar con los rezagos $k = 3, 6, 9$.]. 

De esta manera se puede destacar que las observaciones se encuentran autocorrelacionadas con sus valores de 3, 6 y 9 meses atrás. Este comportamiento sugiere la utilización, en principio, de un SARIMA(3,1,0)(0,0,0), bajo el argumento de que la FAC se comporta como la que presenta un AR(3) con $\phi_1 = \phi_2 = 0$.

En la FACP, en cambio, se observa la significación de los coeficientes asociados a los dos primeros retardos. En conjunto con la significación del $\hat{\rho}_1$ de la FAC es que se plantea la posibilidad de modelar la Estacionalidad por medio de un SARIMA(3,1,0)(0,1,1).

## Dominio de Frecuencias: Análisis del Espectro de la Serie Diferenciada

```{r}
# Espectro de la Serie:
Espectro_Serie_Diferenciada <- spectrum(diff_cantidad_clientes_ts, method = c("ar"), 
                           freq = seq(from = 0, to = 0.5, length.out = 1000), plot = F) 
# Se transforma las frecuencias para el intervalo [0,\pi]:
Espectro_Serie_Diferenciada_Tibble <- tibble(Frecuencias = Espectro_Serie_Diferenciada$freq*pi/max(Espectro_Serie_Diferenciada$freq),
                                Espectro = Espectro_Serie_Diferenciada$spec)
# Plot:
Plot_Espectro_Serie_Diferenciada_Suavizado <- ggplot(Espectro_Serie_Diferenciada_Tibble) +
  geom_line(aes(Frecuencias, Espectro)) +
  labs(x = TeX(r"($\omega$ (Frecuencias))"), 
       y = TeX(r"($S_{X}$(\omega))"),
       title = TeX(r"(Periodograma Suavizado de la Serie Diferenciada)"),
       subtitle = "Método: AR(3)",
       color = "") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) +
  guides(color = guide_legend(position = "bottom"))
Plot_Espectro_Serie_Diferenciada_Suavizado  
```

El Espectro también muestra como la primera diferencia elimina el componente tendencial, al presentar bajos valores en las frecuencias más bajas. No obstante, realza el peso de las frecuencias que se encuentran en torno a $\omega_{\max} = 2.12$.

Considerando que $\text{per}(\omega_j) = \frac{2\pi}{\omega_j}$, entonces se tiene que $\text{per}(\omega_{\max}) \approx 3$, lo que quiere decir que la aplicación de la primera diferencia regular tuvo como resultado el incrementar la importancia de los ciclos que se repiten cada 3 meses a la hora de explicar la variabilidad de la serie.

Sea $j$ el índice de la observación y $T = 75$ la cantidad de observaciones que componen a la serie. Entonces la frecuencia j-ésima viene dada por $\omega_j = \frac{2\pi j}{T}$ con período $\text{per}(\omega_j) = \frac{2\pi}{\omega_j} = \frac{T}{j}$. Considerando la frecuencia de espectro más alto identificada en el párrago anterior se obtiene que^[Dado $\omega_j = 2.12 = \frac{2\pi j}{75}$ y despejando $j$ se obtiene $j_{\max} \approx 25$.] $j_{\max} = 25$ con período $3$.

PREGUNTA: El hecho de que los ciclos que más explican la varianza sean los de período 3 puede ir de la mano con lo que indicaba Lucca de que entran deudores a los 3 meses (2+1).

## Serie Diferenciada de acuerdo a la Primera Diferencia Regular y Primera Diferencia Estacional (Trimestral)
```{r}
diff_estacional <- diff(diff_cantidad_clientes_ts, lag = 3)
```

## Gráfico de la Serie Diferenciada Estacional
```{r}
autoplot(diff_estacional) +
  labs(x = "Fecha", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con Deuda en Santander",
       subtitle = "Primera Diferencia Regular y Primera Diferencia Estacional (Trimestral)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

## FAC y FACP de la Serie Diferenciada (Regular y Estacional)
```{r}
diff_estacional_acf <- ggAcf(diff_estacional, lag.max = 24, type = "correlation") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "FAC de la Serie Diferenciada (Regular y Estacional)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

diff_estacional_pacf <- ggAcf(diff_estacional, lag.max = 24, type = "partial") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "FACP de la Serie Diferenciada (Regular y Estacional)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

grid.arrange(diff_estacional_acf, diff_estacional_pacf)
```

## Serie Diferenciada de acuerdo a la Primera Diferencia Regular y Primera Diferencia Estacional (Anual)
```{r}
diff_estacional_anual <- diff(diff_cantidad_clientes_ts, lag = 12)
```

## Gráfico de la Serie Diferenciada Estacional Anual
```{r}
autoplot(diff_estacional_anual) +
  labs(x = "Fecha", y = "Cantidad de 
       Personas", 
       title = "Serie de Cantidad de Personas con Deuda en Santander",
       subtitle = "Primera Diferencia Regular y Primera Diferencia Estacional (Anual)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())
```

## FAC y FACP de la Serie Diferenciada (Regular y Estacional Anual)
```{r}
diff_estacional_anual_acf <- ggAcf(diff_estacional_anual, lag.max = 24, type = "correlation") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\rho_{k}}$)"), title = "FAC de la Serie Diferenciada (Regular y Estacional Anual)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

diff_estacional_anual_pacf <- ggAcf(diff_estacional_anual, lag.max = 24, type = "partial") +
    labs(x = "k (Rezago)", 
       y = TeX(r"($\hat{\alpha_{k}}$)"), title = "FACP de la Serie Diferenciada (Regular y Estacional Anual)") +
  theme_minimal() +
  theme(axis.title.y = element_text(angle = 0, vjust = 0.5)) + 
  theme(panel.grid.minor = element_blank())

grid.arrange(diff_estacional_anual_acf, diff_estacional_anual_pacf)
```

# Modelos Propuestos

## Exploración del Modelo SARIMA(10,1,0)(0,1,1)[12] con Intervención de Atípicos

Se propone un modelo `SARIMA(10,1,0)(0,1,1)[12]`. Dada la presencia de posibles valores atípicos, primero se realiza una detección y luego se incorporan como variables regresoras en el modelo final.

### Detección y Tratamiento de Atípicos

```{r}
# Se utiliza tso para detectar outliers en un modelo base
outlier_m1_detect <- tso(cantidad_clientes_ts, 
                  cval = 2.5, 
                  types = c("AO", "LS", "TC"), 
                  tsmethod = "arima", 
                  args.tsmethod = list(order = c(3, 1, 0), 
                                       seasonal = list(order = c(0, 1, 1), period = 12), 
                                       include.mean= FALSE))

# kable(outlier_m1_detect$outliers, caption = "Atípicos Detectados para Modelo 1")

# Se crean los regresores para los atípicos identificados
AO_2019_09_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 10), length(cantidad_clientes_ts))
TC_2019_12_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 13), length(cantidad_clientes_ts))
AO_2021_12_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 37), length(cantidad_clientes_ts))
AO_2023_08_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 57), length(cantidad_clientes_ts))
TC_2023_10_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 59), length(cantidad_clientes_ts))
TC_2024_06_m1 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 67), length(cantidad_clientes_ts)) 

xreg_m1 <- cbind(AO_2019_09_m1, TC_2019_12_m1, AO_2021_12_m1, AO_2023_08_m1, TC_2023_10_m1, TC_2024_06_m1)
```

### Ajuste del Modelo

```{r}
modelo_1 <- Arima(y = cantidad_clientes_ts,
                  order = c(10, 1, 0),
                  seasonal = list(order = c(0,1,1), period = 12),
                  fixed = c(0, NA, 0, 0, 0, 0, 0, NA, 0, NA, NA, NA, NA, NA, NA, NA, NA),
                  xreg = xreg_m1,
                  method = "ML")

tbl_regression(modelo_1, exponentiate = FALSE) |>
  modify_caption("Coeficientes del Modelo SARIMA(10,1,0)(0,1,1)[12]")
```

### Criterios de Información y Medidas de Error

```{r}
model_m1_metrics <- data.frame(
  AIC = modelo_1$aic,
  AICc = modelo_1$aicc,
  BIC = modelo_1$bic
)
kable(model_m1_metrics, caption = "Criterios de Información del Modelo 1")

error_measures_m1 <- accuracy(modelo_1) %>% as.data.frame()
kable(error_measures_m1, caption = "Medidas de Error del Modelo 1")
```

### Diagnóstico de Residuos

```{r}
residuos_m1 <- residuals(modelo_1)
autoplot(residuos_m1) +
  labs(x = "Fecha", y = "Residuos", title = "Residuos del Modelo 1") +
  geom_hline(yintercept = 0, color = "red")

residuos_m1_acf <- ggAcf(residuos_m1, lag.max = 24, type = "correlation") +
  labs(title = "FAC de los Residuos del Modelo 1")
residuos_m1_pacf <- ggAcf(residuos_m1, lag.max = 24, type = "partial") +
  labs(title = "FACP de los Residuos del Modelo 1")
grid.arrange(residuos_m1_acf, residuos_m1_pacf)
```

#### Test de Ljung-Box

```{r}
ljung_box_df_m1 <- tibble()
for(i in 3:24){
  ljung_box_df_m1 <- rbind(ljung_box_df_m1, (Box.test(
    residuos_m1, lag = i, type = "Ljung-Box", fitdf = 4) %>% tidy()))
}
kable(ljung_box_df_m1, caption = "Test de Ljung-Box para Residuos del Modelo 1 (Rezagos 3-24)")
```

#### Análisis de Homocedasticidad y Normalidad

```{r}
residuos_m1_sq <- residuos_m1^2
autoplot(residuos_m1_sq) + labs(title = "Cuadrado de los Residuos del Modelo 1")
ggAcf(residuos_m1_sq, type = "correlation") + labs(title = "FAC del Cuadrado de los Residuos del Modelo 1")

ggplot(data.frame(residuos = residuos_m1), aes(sample = residuos)) +
  stat_qq() + stat_qq_line(color = "red") +
  labs(title = "QQ-plot de Residuos del Modelo 1")

shapiro_test_m1 <- shapiro.test(residuos_m1) |> tidy()
jarque_bera_test_m1 <- jarque.bera.test(residuos_m1) |> tidy()
normalidad_m1 <- dplyr::bind_rows(
  "Shapiro-Wilk" = shapiro_test_m1,
  "Jarque-Bera" = jarque_bera_test_m1,
  .id = "Test"
)
kable(normalidad_m1, caption = "Tests de Normalidad para Residuos del Modelo 1")
```

## Exploración del Modelo SARIMA(1,1,0)(1,1,0)[3] en Logaritmos con Intervención de Atípicos

Para este modelo, se transforma la serie aplicando logaritmos para estabilizar la varianza. Luego, se ajusta un modelo `SARIMA(1,1,0)(1,1,0)[3]` con una periodicidad trimestral y se realiza un tratamiento de atípicos.

### Transformación y Detección de Atípicos

```{r}
cantidad_clientes_ts_log <- log(cantidad_clientes_ts)

# Detección de atípicos en la serie logarítmica
outlier_m2_detect <- tso(cantidad_clientes_ts_log, 
                  cval = 2.5, 
                  types = c("AO", "LS", "TC"), 
                  tsmethod = "arima", 
                  args.tsmethod = list(order = c(1, 1, 0),
                                       seasonal = list(order = c(1,1,0), period = 3),
                                       include.mean= FALSE))
# kable(outlier_m2_detect$outliers, caption = "Atípicos Detectados para Modelo 2 (Log)")

# Creación de regresores para atípicos
AO_2019_09_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 10), length(cantidad_clientes_ts_log))
TC_2019_12_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 13), length(cantidad_clientes_ts_log))
TC_2021_12_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 37), length(cantidad_clientes_ts_log))
LS_2023_03_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "LS", ind = 52), length(cantidad_clientes_ts_log))
AO_2023_08_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 57), length(cantidad_clientes_ts_log))
TC_2023_10_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 59), length(cantidad_clientes_ts_log))
TC_2024_06_m2 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 67), length(cantidad_clientes_ts_log)) 

xreg_m2 <- cbind(AO_2019_09_m2, TC_2019_12_m2, TC_2021_12_m2, LS_2023_03_m2, AO_2023_08_m2, TC_2023_10_m2, TC_2024_06_m2)
```

### Ajuste del Modelo

```{r}
modelo_2 <- Arima(y = cantidad_clientes_ts_log,
                  order = c(1, 1, 0),
                  seasonal = list(order = c(1,1,0), period = 3),
                  xreg = xreg_m2,
                  fixed = c(0, NA, NA, NA, NA, NA, NA, NA, NA),
                  method = "ML")

tbl_regression(modelo_2, exponentiate = FALSE) |>
  modify_caption("Coeficientes del Modelo SARIMA(1,1,0)(1,1,0)[3] (Log)")
```

### Criterios de Información y Medidas de Error

```{r}
model_m2_metrics <- data.frame(
  AIC = modelo_2$aic,
  AICc = modelo_2$aicc,
  BIC = modelo_2$bic
)
kable(model_m2_metrics, caption = "Criterios de Información del Modelo 2 (Log)")

error_measures_m2 <- accuracy(modelo_2) %>% as.data.frame()
kable(error_measures_m2, caption = "Medidas de Error del Modelo 2 (Log)")
```

### Diagnóstico de Residuos

```{r}
residuos_m2 <- residuals(modelo_2)
autoplot(residuos_m2) +
  labs(x = "Fecha", y = "Residuos", title = "Residuos del Modelo 2 (Log)") +
  geom_hline(yintercept = 0, color = "red")

residuos_m2_acf <- ggAcf(residuos_m2, lag.max = 24, type = "correlation") +
  labs(title = "FAC de los Residuos del Modelo 2 (Log)")
residuos_m2_pacf <- ggAcf(residuos_m2, lag.max = 24, type = "partial") +
  labs(title = "FACP de los Residuos del Modelo 2 (Log)")
grid.arrange(residuos_m2_acf, residuos_m2_pacf)
```

#### Test de Ljung-Box

```{r}
ljung_box_df_m2 <- tibble()
for(i in 3:24){
  ljung_box_df_m2 <- rbind(ljung_box_df_m2, (Box.test(
    residuos_m2, lag = i, type = "Ljung-Box", fitdf = 1) %>% tidy()))
}
kable(ljung_box_df_m2, caption = "Test de Ljung-Box para Residuos del Modelo 2 (Log, Rezagos 3-24)")
```

#### Análisis de Homocedasticidad y Normalidad

```{r}
residuos_m2_sq <- residuos_m2^2
autoplot(residuos_m2_sq) + labs(title = "Cuadrado de los Residuos del Modelo 2 (Log)")
ggAcf(residuos_m2_sq, type = "correlation") + labs(title = "FAC del Cuadrado de los Residuos del Modelo 2 (Log)")

ggplot(data.frame(residuos = residuos_m2), aes(sample = residuos)) +
  stat_qq() + stat_qq_line(color = "red") +
  labs(title = "QQ-plot de Residuos del Modelo 2 (Log)")

shapiro_test_m2 <- shapiro.test(residuos_m2) |> tidy()
jarque_bera_test_m2 <- jarque.bera.test(residuos_m2) |> tidy()
normalidad_m2 <- dplyr::bind_rows(
  "Shapiro-Wilk" = shapiro_test_m2,
  "Jarque-Bera" = jarque_bera_test_m2,
  .id = "Test"
)
kable(normalidad_m2, caption = "Tests de Normalidad para Residuos del Modelo 2 (Log)")
```

## Exploración del Modelo SARIMA(2,1,0)(0,1,1)[12] con Intervención de Atípicos

Finalmente, se explora un modelo `SARIMA(2,1,0)(0,1,1)[12]`. Este modelo se especifica como un `(3,1,0)` con coeficientes fijados en cero para `ar1` y `ar3`, y también incluye el tratamiento de valores atípicos.

### Detección y Tratamiento de Atípicos

```{r}
# Detección de atípicos en un modelo base
outlier_m3_detect <- tso(cantidad_clientes_ts, 
                  cval = 2.5, 
                  types = c("AO", "LS", "TC"), 
                  tsmethod = "arima", 
                  args.tsmethod = list(order = c(3, 1, 0), include.mean= FALSE))
# kable(outlier_m3_detect$outliers, caption = "Atípicos Detectados para Modelo 3")

# Creación de regresores para atípicos
AO_2019_09_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 10), length(cantidad_clientes_ts))
TC_2019_12_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 13), length(cantidad_clientes_ts))
TC_2021_12_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 37), length(cantidad_clientes_ts))
AO_2023_02_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 51), length(cantidad_clientes_ts))
AO_2023_08_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "AO", ind = 57), length(cantidad_clientes_ts))
TC_2023_10_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 59), length(cantidad_clientes_ts))
TC_2024_06_m3 <- tsoutliers::outliers.effects(tsoutliers::outliers(type = "TC", ind = 67), length(cantidad_clientes_ts)) 

xreg_m3 <- cbind(AO_2019_09_m3, TC_2019_12_m3, TC_2021_12_m3, AO_2023_02_m3, AO_2023_08_m3, TC_2023_10_m3, TC_2024_06_m3)
```

### Ajuste del Modelo

```{r}
modelo_3 <- Arima(y = cantidad_clientes_ts,
                  order = c(3, 1, 0),
                  seasonal = list(order = c(0,1,1), period = 12),
                  fixed = c(0, NA, 0, NA, NA, NA, NA, NA, NA, NA, NA),
                  xreg = xreg_m3,
                  method = "ML")
                  
tbl_regression(modelo_3, exponentiate = FALSE) |>
  modify_caption("Coeficientes del Modelo SARIMA(2,1,0)(0,1,1)[12]")
```

### Criterios de Información y Medidas de Error

```{r}
model_m3_metrics <- data.frame(
  AIC = modelo_3$aic,
  AICc = modelo_3$aicc,
  BIC = modelo_3$bic
)
kable(model_m3_metrics, caption = "Criterios de Información del Modelo 3")

error_measures_m3 <- accuracy(modelo_3) %>% as.data.frame()
kable(error_measures_m3, caption = "Medidas de Error del Modelo 3")
```

### Diagnóstico de Residuos

```{r}
residuos_m3 <- residuals(modelo_3)
autoplot(residuos_m3) +
  labs(x = "Fecha", y = "Residuos", title = "Residuos del Modelo 3") +
  geom_hline(yintercept = 0, color = "red")

residuos_m3_acf <- ggAcf(residuos_m3, lag.max = 24, type = "correlation") +
  labs(title = "FAC de los Residuos del Modelo 3")
residuos_m3_pacf <- ggAcf(residuos_m3, lag.max = 24, type = "partial") +
  labs(title = "FACP de los Residuos del Modelo 3")
grid.arrange(residuos_m3_acf, residuos_m3_pacf)
```

#### Test de Ljung-Box

```{r}
ljung_box_df_m3 <- tibble()
for(i in 3:24){
  ljung_box_df_m3 <- rbind(ljung_box_df_m3, (Box.test(
    residuos_m3, lag = i, type = "Ljung-Box", fitdf = 2) %>% tidy()))
}
kable(ljung_box_df_m3, caption = "Test de Ljung-Box para Residuos del Modelo 3 (Rezagos 3-24)")
```

#### Análisis de Homocedasticidad y Normalidad

```{r}
residuos_m3_sq <- residuos_m3^2
autoplot(residuos_m3_sq) + labs(title = "Cuadrado de los Residuos del Modelo 3")
ggAcf(residuos_m3_sq, type = "correlation") + labs(title = "FAC del Cuadrado de los Residuos del Modelo 3")

ggplot(data.frame(residuos = residuos_m3), aes(sample = residuos)) +
  stat_qq() + stat_qq_line(color = "red") +
  labs(title = "QQ-plot de Residuos del Modelo 3")

shapiro_test_m3 <- shapiro.test(residuos_m3) |> tidy()
jarque_bera_test_m3 <- jarque.bera.test(residuos_m3) |> tidy()
normalidad_m3 <- dplyr::bind_rows(
  "Shapiro-Wilk" = shapiro_test_m3,
  "Jarque-Bera" = jarque_bera_test_m3,
  .id = "Test"
)
kable(normalidad_m3, caption = "Tests de Normalidad para Residuos del Modelo 3")
```


## Comparación de Modelos SARIMA
